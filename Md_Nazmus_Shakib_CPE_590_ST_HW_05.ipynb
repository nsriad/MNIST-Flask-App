{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Machine Learning Deployment for MNIST Dataset**"
      ],
      "metadata": {
        "id": "HHZ0LtTh9gLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.1 Convolutional Neural Network for MNIST Dataset**"
      ],
      "metadata": {
        "id": "HSgeGF6V9vzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.1 Load and Normalize MNIST Dataset**"
      ],
      "metadata": {
        "id": "iBWHAgxu91gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwdKsYmCAXpv",
        "outputId": "e911c4ec-39cc-44de-f7eb-f00e7a5d316c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J1XzgaaZ4SZ5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import onnx\n",
        "import torch.onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts image to tensor\n",
        "    transforms.Normalize((0.0,), (1.0,))  # Normalize pixels to 0-1\n",
        "])\n",
        "\n",
        "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd0qKZHj_2HR",
        "outputId": "cd628b22-69b2-4307-fcd6-f070db920c45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 117MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 21.8MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 90.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.47MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.2 Dividing the dataset into training and test set**"
      ],
      "metadata": {
        "id": "9eIHfnW8-3jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.67 * len(mnist_data))\n",
        "test_size = len(mnist_data) - train_size\n",
        "train_data, test_data = random_split(mnist_data, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "7CtMdeQa-fnB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.3 Implementing CNN model**"
      ],
      "metadata": {
        "id": "CI_-D_nyBMPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))  # 28->26\n",
        "        x = self.pool1(x)              # 26->13\n",
        "        x = torch.relu(self.conv2(x))  # 13->11\n",
        "        x = self.pool2(x)              # 11->5\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "AJWAlQA9BSQn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.4 Compiling and Training the model**"
      ],
      "metadata": {
        "id": "T2GAdA4fC6vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNIST_CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "_YGgk5gVC-KH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eajdmFr4DMdk",
        "outputId": "8231448f-6f77-4c52-ae33-a005bb8b4e28"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 391.8843\n",
            "Epoch 2, Loss: 150.6327\n",
            "Epoch 3, Loss: 111.6623\n",
            "Epoch 4, Loss: 96.3595\n",
            "Epoch 5, Loss: 78.1042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.5 Implementing Learning rate scheduling**"
      ],
      "metadata": {
        "id": "b-rw0H17Fkc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the model\n",
        "model = MNIST_CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initial learning rate\n",
        "lr = 0.001\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    # Create optimizer with current learning rate\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Learning Rate: {lr:.6f}\")\n",
        "    # Reduce learning rate by 10%\n",
        "    lr = lr * 0.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb4pDa0tFpqm",
        "outputId": "c1ea43ce-f002-4d91-cff8-3d02f5fd970f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 354.6176, Learning Rate: 0.001000\n",
            "Epoch [2/50], Loss: 126.9343, Learning Rate: 0.000900\n",
            "Epoch [3/50], Loss: 88.5674, Learning Rate: 0.000810\n",
            "Epoch [4/50], Loss: 72.4636, Learning Rate: 0.000729\n",
            "Epoch [5/50], Loss: 55.0390, Learning Rate: 0.000656\n",
            "Epoch [6/50], Loss: 45.5342, Learning Rate: 0.000590\n",
            "Epoch [7/50], Loss: 38.6938, Learning Rate: 0.000531\n",
            "Epoch [8/50], Loss: 33.1034, Learning Rate: 0.000478\n",
            "Epoch [9/50], Loss: 27.2990, Learning Rate: 0.000430\n",
            "Epoch [10/50], Loss: 24.7213, Learning Rate: 0.000387\n",
            "Epoch [11/50], Loss: 20.4841, Learning Rate: 0.000349\n",
            "Epoch [12/50], Loss: 17.5415, Learning Rate: 0.000314\n",
            "Epoch [13/50], Loss: 17.1221, Learning Rate: 0.000282\n",
            "Epoch [14/50], Loss: 15.4953, Learning Rate: 0.000254\n",
            "Epoch [15/50], Loss: 14.7315, Learning Rate: 0.000229\n",
            "Epoch [16/50], Loss: 13.0253, Learning Rate: 0.000206\n",
            "Epoch [17/50], Loss: 12.2188, Learning Rate: 0.000185\n",
            "Epoch [18/50], Loss: 10.4764, Learning Rate: 0.000167\n",
            "Epoch [19/50], Loss: 10.1980, Learning Rate: 0.000150\n",
            "Epoch [20/50], Loss: 9.4238, Learning Rate: 0.000135\n",
            "Epoch [21/50], Loss: 9.3248, Learning Rate: 0.000122\n",
            "Epoch [22/50], Loss: 9.5024, Learning Rate: 0.000109\n",
            "Epoch [23/50], Loss: 8.7223, Learning Rate: 0.000098\n",
            "Epoch [24/50], Loss: 6.7741, Learning Rate: 0.000089\n",
            "Epoch [25/50], Loss: 6.2948, Learning Rate: 0.000080\n",
            "Epoch [26/50], Loss: 6.9279, Learning Rate: 0.000072\n",
            "Epoch [27/50], Loss: 5.9136, Learning Rate: 0.000065\n",
            "Epoch [28/50], Loss: 6.1793, Learning Rate: 0.000058\n",
            "Epoch [29/50], Loss: 6.9680, Learning Rate: 0.000052\n",
            "Epoch [30/50], Loss: 6.2535, Learning Rate: 0.000047\n",
            "Epoch [31/50], Loss: 6.0459, Learning Rate: 0.000042\n",
            "Epoch [32/50], Loss: 5.4273, Learning Rate: 0.000038\n",
            "Epoch [33/50], Loss: 5.9146, Learning Rate: 0.000034\n",
            "Epoch [34/50], Loss: 5.7007, Learning Rate: 0.000031\n",
            "Epoch [35/50], Loss: 5.1483, Learning Rate: 0.000028\n",
            "Epoch [36/50], Loss: 5.4345, Learning Rate: 0.000025\n",
            "Epoch [37/50], Loss: 4.7619, Learning Rate: 0.000023\n",
            "Epoch [38/50], Loss: 4.9426, Learning Rate: 0.000020\n",
            "Epoch [39/50], Loss: 5.5010, Learning Rate: 0.000018\n",
            "Epoch [40/50], Loss: 5.1427, Learning Rate: 0.000016\n",
            "Epoch [41/50], Loss: 5.4570, Learning Rate: 0.000015\n",
            "Epoch [42/50], Loss: 4.4183, Learning Rate: 0.000013\n",
            "Epoch [43/50], Loss: 4.5461, Learning Rate: 0.000012\n",
            "Epoch [44/50], Loss: 5.2037, Learning Rate: 0.000011\n",
            "Epoch [45/50], Loss: 4.9412, Learning Rate: 0.000010\n",
            "Epoch [46/50], Loss: 4.7779, Learning Rate: 0.000009\n",
            "Epoch [47/50], Loss: 4.7636, Learning Rate: 0.000008\n",
            "Epoch [48/50], Loss: 4.3957, Learning Rate: 0.000007\n",
            "Epoch [49/50], Loss: 5.1752, Learning Rate: 0.000006\n",
            "Epoch [50/50], Loss: 5.2072, Learning Rate: 0.000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting test dataset to a single tensor\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    X_test.append(images)\n",
        "    y_test.append(labels)\n",
        "\n",
        "# stacking all the batches into full tensors\n",
        "X_test_tensor = torch.cat(X_test, dim=0)\n",
        "y_test_tensor = torch.cat(y_test, dim=0)\n",
        "\n",
        "# evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJOa4WxKIqlb",
        "outputId": "cd1c3c33-8ec6-4e59-c883-40a2e3c8da4a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.6 Saving the model as ONNX format**"
      ],
      "metadata": {
        "id": "xpPvESPXMm05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Pick 5 random indices\n",
        "random_indices = random.sample(range(len(test_data)), 15)\n",
        "\n",
        "samples = []\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    image, label = test_data[idx]\n",
        "    image_np = image.squeeze().numpy()\n",
        "    samples.append((image_np, label))\n",
        "    plt.imshow(image_np, cmap='gray')\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"sample_{i}.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "5xmi7tYpF0Nw",
        "outputId": "5311e3ff-0185-493d-fbeb-569703864242"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx\n",
        "\n",
        "# dummy input tensor of the correct shape: (batch_size=1, channels=1, height=28, width=28)\n",
        "dummy_input = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "# Export to ONNX format\n",
        "torch.onnx.export(\n",
        "    model,                          #trained model\n",
        "    dummy_input,                    # dummy input for tracing\n",
        "    \"mnist_cnn.onnx\",              # output file name\n",
        "    input_names=['input'],         # input name\n",
        "    output_names=['output'],       # output name\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},  # optional, but good\n",
        "    opset_version=11               # ONNX opset version\n",
        ")\n",
        "\n",
        "print(\"Model saved as mnist_cnn.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgHp-c37Qyhr",
        "outputId": "ce8854ed-4164-489b-fa84-a9e58ae89949"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as mnist_cnn.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.7 Loading ONNX model**"
      ],
      "metadata": {
        "id": "LCTvjZf1Lzzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEsQvrLBLwsZ",
        "outputId": "65132010-0b1e-4a29-ec0c-a79df3538c6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Load ONNX model\n",
        "session = ort.InferenceSession(\"mnist_cnn.onnx\")\n",
        "\n",
        "# Pick a sample from the saved images\n",
        "sample_image, true_label = samples[0]  # Using sample_0.png\n",
        "\n",
        "# image processing for input\n",
        "input_tensor = np.expand_dims(np.expand_dims(sample_image, axis=0), axis=0).astype(np.float32)\n",
        "\n",
        "# Run inference\n",
        "inputs = {session.get_inputs()[0].name: input_tensor}\n",
        "outputs = session.run(None, inputs)\n",
        "logits = outputs[0]\n",
        "\n",
        "# Get predicted label\n",
        "predicted_label = np.argmax(logits)\n",
        "\n",
        "# Print result\n",
        "print(f\"True Label     : {true_label}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIM6hvDOMAjV",
        "outputId": "9af51796-b2e7-4470-8d3e-b8736f14c8dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label     : 1\n",
            "Predicted Label: 1\n"
          ]
        }
      ]
    }
  ]
}